{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bBVmibRKQwjg"
   },
   "outputs": [],
   "source": [
    "# pip install umap-learn hdbscan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yKQU5FlyfJBc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 13:55:50.400478: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import os\n",
    "import tarfile\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import confusion_matrix, adjusted_rand_score, adjusted_mutual_info_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from umap import UMAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "bvntE-XhfNWn"
   },
   "outputs": [],
   "source": [
    "filename = './flowers_features_and_labels.npz'\n",
    "\n",
    "if os.path.exists(filename):\n",
    "    file = np.load(filename)\n",
    "    X_all, labels_true = file['f_all'], file['y_all']\n",
    "\n",
    "else:\n",
    "    if not os.path.exists('./flower_photos'):\n",
    "        # download the flowers dataset and extract its images\n",
    "        url = 'http://download.tensorflow.org/example_images/flower_photos.tgz'\n",
    "        with open('./flower_photos.tgz', 'wb') as file:\n",
    "            file.write(requests.get(url).content)\n",
    "        with tarfile.open('./flower_photos.tgz') as file:\n",
    "            file.extractall('./')\n",
    "        os.remove('./flower_photos.tgz')\n",
    "\n",
    "    class FeatureExtractor(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "            vgg = torch.hub.load('pytorch/vision:v0.10.0', 'vgg16', pretrained=True)\n",
    "\n",
    "            # Extract VGG-16 Feature Layers\n",
    "            self.features = list(vgg.features)\n",
    "            self.features = nn.Sequential(*self.features)\n",
    "            # Extract VGG-16 Average Pooling Layer\n",
    "            self.pooling = vgg.avgpool\n",
    "            # Convert the image into one-dimensional vector\n",
    "            self.flatten = nn.Flatten()\n",
    "            # Extract the first part of fully-connected layer from VGG16\n",
    "            self.fc = vgg.classifier[0]\n",
    "\n",
    "        def forward(self, x):\n",
    "            # It will take the input 'x' until it returns the feature vector called 'out'\n",
    "            out = self.features(x)\n",
    "            out = self.pooling(out)\n",
    "            out = self.flatten(out)\n",
    "            out = self.fc(out)\n",
    "            return out\n",
    "\n",
    "    # Initialize the model\n",
    "    assert torch.cuda.is_available()\n",
    "    feature_extractor = FeatureExtractor().cuda().eval()\n",
    "\n",
    "    dataset = datasets.ImageFolder(root='./flower_photos',\n",
    "                                   transform=transforms.Compose([transforms.Resize(224),\n",
    "                                                                 transforms.CenterCrop(224),\n",
    "                                                                 transforms.ToTensor(),\n",
    "                                                                 transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))\n",
    "    dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    # Extract features and store them on disk\n",
    "    X_all, labels_true = np.zeros((0, 4096)), np.zeros((0,))\n",
    "    for x, y in tqdm(dataloader):\n",
    "        with torch.no_grad():\n",
    "            X_all = np.vstack([X_all, feature_extractor(x.cuda()).cpu()])\n",
    "            labels_true = np.concatenate([labels_true, y])\n",
    "    np.savez(filename, f_all=labels_true, y_all=labels_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y2_isGa4hDW3",
    "outputId": "7cbed9f7-e69a-4c7c-8dc2-da41b9c91012"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3670, 4096) (3670,)\n"
     ]
    }
   ],
   "source": [
    "print(X_all.shape, labels_true.shape)\n",
    "num_features = X_all.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-cWAfwzo1qe"
   },
   "source": [
    "### QUESTION 19:\n",
    "- <font color='red'>In a brief paragraph discuss: If the VGG network is trained on a dataset with perhaps totally different classes as targets, why would one expect the features derived from such a network to have discriminative power for a custom dataset?\n",
    "\n",
    "Convolutional neural networks (CNNs) consist of two main parts: one that extracts features from RGB images using convolutional filters, and another that classifies these features using a fully-connected neural network. In VGG networks, early layers learn simple features like edges, while later layers focus on complex shapes and object parts. Features learned by CNNs, especially lower-level ones, are generally versatile and useful for different datasets, making them suitable for tasks like clustering. Pre-trained CNNs act as experienced agents adept at recognizing key features for image understanding.\n",
    "\n",
    "\n",
    "### QUESTION 20:\n",
    "- <font color='red'>In a brief paragraph explain how the helper code base is performing feature extraction.\n",
    "\n",
    "First, it defines a FeatureExtractor class that encapsulates specific layers of the VGG-16 model necessary for feature extraction, including convolutional (features), average pooling (pooling), flattening (flatten), and the first fully-connected layer (fc). Then, it sets up an image dataset (ImageFolder) from the flower_photos directory with defined transformations for resizing, center cropping, and normalization. Using a DataLoader, the code iterates through batches of images, applies the FeatureExtractor to extract features from each image batch, and accumulates these features (f_all) along with corresponding labels (y_all).\n",
    "\n",
    "\n",
    "### QUESTION 21:\n",
    "- <font color='red'>How many pixels are there in the original images? How many features does the VGG network extract per image; i.e what is the dimension of each feature vector for an image sample?\n",
    "\n",
    "There are 32400 = 180*180 pixels in the original image. Dimension of the each image after using VGG network reduced to 4096.\n",
    "\n",
    "\n",
    "### QUESTION 22:\n",
    "- <font color='red'>Are the extracted features dense or sparse? (Compare with sparse TF-IDF features in text.)\n",
    "\n",
    "When we use the VGG-16 model as a feature extractor, it processes each input image through its convolutional layers, pooling layers, and fully-connected layers.\n",
    "The output of these layers for each image is a dense, fixed-size feature vector (4096). Dense features contain numerical values (floating-point numbers) for each dimension of the feature vector, representing learned patterns and characteristics of the input image. Sparse features, in contrast, contain mostly zeros with a few non-zero values. They are typical in scenarios where the data is inherently sparse, such as text data represented using techniques like TF-IDF.\n",
    "\n",
    "### QUESTION 23:\n",
    "Map the features you have extracted onto 2 dimensions with t-SNE. Then plot the mapped feature vectors along x and y axes. Color-code the data points with ground-truth labels. Describe your observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "id": "7Nbuq9SphEk6",
    "outputId": "5fea697e-a725-43c7-c8c3-f0e34027cdf6"
   },
   "outputs": [],
   "source": [
    "\n",
    "filename = './flowers_features_and_labels.npz'\n",
    "data = np.load(filename)\n",
    "X_all, labels_true = data['f_all'], data['y_all']\n",
    "\n",
    "# Initialize t-SNE with 2 output dimensions\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "# Fit and transform the features to 2D space\n",
    "features_2d = tsne.fit_transform(X_all)\n",
    "\n",
    "# Extract unique labels and corresponding colors\n",
    "unique_labels = np.unique(labels_true)\n",
    "num_labels = len(unique_labels)\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, num_labels))  # Generate colors for each label\n",
    "\n",
    "# Plot each data point with its label as color\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i, label in enumerate(unique_labels):\n",
    "    indices = (labels_true == label)\n",
    "    plt.scatter(features_2d[indices, 0], features_2d[indices, 1], color=colors[i], label=str(label))\n",
    "\n",
    "plt.title('t-SNE Visualization of Extracted Features')\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "plt.legend(title='Ground Truth Label', loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EgZ_YkYI8mNN"
   },
   "source": [
    "Two most informative component of extracted features are capable of making distinction between four classes (0,1,2,3) of flower images. The fifth class (4) coincide with the rest of the classes especially with class number 2.\n",
    "\n",
    "### Question 24\n",
    "Report the best result (in terms of rand score) within the table below.\n",
    "For HDBSCAN, introduce a conservative parameter grid over min cluster size and min samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "jXqhxY-R8l83"
   },
   "outputs": [],
   "source": [
    "class Autoencoder(torch.nn.Module, TransformerMixin):\n",
    "    def __init__(self, n_components):\n",
    "        super().__init__()\n",
    "        self.n_components = n_components\n",
    "        self.n_features = None  # to be determined with data\n",
    "        self.encoder = None\n",
    "        self.decoder = None\n",
    "\n",
    "    def _create_encoder(self):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(4096, 1280),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1280, 640),\n",
    "            nn.ReLU(True), nn.Linear(640, 120), nn.ReLU(True), nn.Linear(120, self.n_components))\n",
    "\n",
    "    def _create_decoder(self):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(self.n_components, 120),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(120, 640),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(640, 1280),\n",
    "            nn.ReLU(True), nn.Linear(1280, 4096))\n",
    "\n",
    "    def forward(self, X):\n",
    "        encoded = self.encoder(X)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "    def fit(self, X):\n",
    "        X = torch.tensor(X, dtype=torch.float32, device='cuda')\n",
    "        self.n_features = X.shape[1]\n",
    "        self.encoder = self._create_encoder()\n",
    "        self.decoder = self._create_decoder()\n",
    "        self.cuda()\n",
    "        self.train()\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "        dataset = TensorDataset(X)\n",
    "        dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "        for epoch in tqdm(range(100)):\n",
    "            for (X_,) in dataloader:\n",
    "                X_ = X_.cuda()\n",
    "                # ===================forward=====================\n",
    "                output = self(X_)\n",
    "                loss = criterion(output, X_)\n",
    "                # ===================backward====================\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = torch.tensor(X, dtype=torch.float32, device='cuda')\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            return self.encoder(X).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wa2k8CF4ca7e",
    "outputId": "12d9d712-51bd-4890-fbd7-712a0c5f5f3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rand Index when there is no reduction of dimension: 0.19121276376559876\n"
     ]
    }
   ],
   "source": [
    "# Perform clustering without reduction of dimension\n",
    "clusterer = KMeans(n_clusters=5, max_iter=1000,\n",
    "        n_init=30, random_state=42)\n",
    "\n",
    "labels_pred = clusterer.fit_predict(X_all)\n",
    "ari = adjusted_rand_score(labels_true, labels_pred)\n",
    "print('Rand Index when there is no reduction of dimension:', ari)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-249_V075Ha",
    "outputId": "efb20db8-1da3-469d-a5d4-3a05822b81aa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/umap/umap_.py:1945: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n",
      "/usr/local/lib/python3.10/dist-packages/umap/umap_.py:1945: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n",
      "/usr/local/lib/python3.10/dist-packages/umap/umap_.py:1945: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n",
      "100%|██████████| 100/100 [00:19<00:00,  5.10it/s]\n",
      "100%|██████████| 100/100 [00:18<00:00,  5.31it/s]\n",
      "100%|██████████| 100/100 [00:18<00:00,  5.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduction Method: SVD, Clustering Method: KMeans, ARI: 0.19426467285950377\n",
      "Reduction Method: SVD, Clustering Method: Agglomerative, ARI: 0.22825995103004965\n",
      "Reduction Method: SVD, Clustering Method: HDBSCAN, ARI: 0.0\n",
      "Reduction Method: UMAP, Clustering Method: KMeans, ARI: 0.4165509205988447\n",
      "Reduction Method: UMAP, Clustering Method: Agglomerative, ARI: 0.3722445177451581\n",
      "Reduction Method: UMAP, Clustering Method: HDBSCAN, ARI: -0.0007002455807158757\n",
      "Reduction Method: Autoencoder, Clustering Method: KMeans, ARI: 0.22146499483979495\n",
      "Reduction Method: Autoencoder, Clustering Method: Agglomerative, ARI: 0.2792462980642481\n",
      "Reduction Method: Autoencoder, Clustering Method: HDBSCAN, ARI: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def perform_clustering_with_reduction(reduction_method, clustering_method, X, labels_true, n_components=50):\n",
    "    # Perform dimensionality reduction\n",
    "    if reduction_method == 'SVD':\n",
    "        reducer = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "        X_reduced = reducer.fit_transform(X)  # Apply reduction to the data\n",
    "    elif reduction_method == 'UMAP':\n",
    "        reducer = UMAP(n_components=n_components, random_state=42)\n",
    "        X_reduced = reducer.fit_transform(X)  # Apply reduction to the data\n",
    "    elif reduction_method == 'Autoencoder':\n",
    "        # Assuming Autoencoder class is defined as shown in previous code snippet\n",
    "        autoencoder = Autoencoder(n_components=n_components)\n",
    "        autoencoder.fit(X)\n",
    "        X_reduced = autoencoder.transform(X)\n",
    "\n",
    "\n",
    "    # Perform clustering\n",
    "    if clustering_method == 'KMeans':\n",
    "        clusterer = KMeans(n_clusters=5, max_iter=1000,\n",
    "        n_init=30, random_state=42)\n",
    "    elif clustering_method == 'Agglomerative':\n",
    "        clusterer = AgglomerativeClustering(n_clusters=5, metric='euclidean', linkage='ward')\n",
    "    elif clustering_method == 'HDBSCAN':\n",
    "        clusterer = hdbscan.HDBSCAN(min_cluster_size=10)\n",
    "\n",
    "    labels_pred = clusterer.fit_predict(X_reduced)\n",
    "\n",
    "    # Evaluate clustering performance using Adjusted Rand Index (ARI)\n",
    "    ari = adjusted_rand_score(labels_true, labels_pred)\n",
    "    return ari\n",
    "\n",
    "# List of dimensionality reduction and clustering methods to consider\n",
    "reduction_methods = ['SVD', 'UMAP', 'Autoencoder']\n",
    "clustering_methods = ['KMeans', 'Agglomerative', 'HDBSCAN']\n",
    "\n",
    "# Load the pre-computed features and labels\n",
    "filename = './flowers_features_and_labels.npz'\n",
    "data = np.load(filename)\n",
    "X_all, labels_true = data['f_all'], data['y_all']\n",
    "\n",
    "# Perform clustering with each combination of reduction and clustering method\n",
    "results = []\n",
    "for reduction_method in reduction_methods:\n",
    "    for clustering_method in clustering_methods:\n",
    "        ari = perform_clustering_with_reduction(reduction_method, clustering_method, X_all, labels_true)\n",
    "        results.append((reduction_method, clustering_method, ari))\n",
    "\n",
    "# Display results\n",
    "for reduction_method, clustering_method, ari in results:\n",
    "    print(f\"Reduction Method: {reduction_method}, Clustering Method: {clustering_method}, ARI: {ari}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "NKH28TtM0qzC"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # Ignore all warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O3SbS59RHMvs",
    "outputId": "056e1774-e276-43ae-8441-cea45276153f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD 80 50\n",
      "Estimated number of clusters: 0\n",
      "Estimated number of noise points: 3670\n",
      "ari: 1.0\n",
      "SVD 90 50\n",
      "Estimated number of clusters: 0\n",
      "Estimated number of noise points: 3670\n",
      "ari: 1.0\n",
      "SVD 100 50\n",
      "Estimated number of clusters: 0\n",
      "Estimated number of noise points: 3670\n",
      "ari: 1.0\n",
      "UMAP 80 50\n",
      "Estimated number of clusters: 5\n",
      "Estimated number of noise points: 1312\n",
      "ari: 0.6216258784907273\n",
      "UMAP 90 50\n",
      "Estimated number of clusters: 5\n",
      "Estimated number of noise points: 1312\n",
      "ari: 0.6216258784907273\n",
      "UMAP 100 50\n",
      "Estimated number of clusters: 5\n",
      "Estimated number of noise points: 1312\n",
      "ari: 0.6216258784907273\n",
      "Autoencoder 80 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 0\n",
      "Estimated number of noise points: 3670\n",
      "ari: 1.0\n",
      "Autoencoder 90 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 0\n",
      "Estimated number of noise points: 3670\n",
      "ari: 1.0\n",
      "Autoencoder 100 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:20<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 0\n",
      "Estimated number of noise points: 3670\n",
      "ari: 1.0\n"
     ]
    }
   ],
   "source": [
    "def perform_clustering_with_reduction(reduction_method, X, labels_true, n_components=50,\n",
    "                                      min_cluster_size=10, min_samples=1):\n",
    "    # Perform dimensionality reduction\n",
    "    if reduction_method == 'SVD':\n",
    "        reducer = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "        X_reduced = reducer.fit_transform(X)\n",
    "    elif reduction_method == 'UMAP':\n",
    "        reducer = UMAP(n_components=n_components, random_state=42)\n",
    "        X_reduced = reducer.fit_transform(X)\n",
    "    elif reduction_method == 'Autoencoder':\n",
    "        # Assuming Autoencoder class is defined as shown in previous code snippet\n",
    "        autoencoder = Autoencoder(n_components=n_components)\n",
    "        autoencoder.fit(X)\n",
    "        X_reduced = autoencoder.transform(X)\n",
    "\n",
    "    # Perform clustering with HDBSCAN\n",
    "    clusterer = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size, min_samples=min_samples)\n",
    "    labels_pred = clusterer.fit_predict(X_reduced)\n",
    "\n",
    "    # Number of clusters in labels, ignoring noise if present.\n",
    "    n_clusters_ = len(set(labels_pred)) - (1 if -1 in labels_pred else 0)\n",
    "    n_noise_ = list(labels_pred).count(-1)\n",
    "\n",
    "    print(\"Estimated number of clusters: %d\" % n_clusters_)\n",
    "    print(\"Estimated number of noise points: %d\" % n_noise_)\n",
    "\n",
    "\n",
    "    # Filter out noise points (labels_pred == -1)\n",
    "    valid_indices = labels_pred != -1\n",
    "    filtered_labels_true = labels_true[valid_indices]\n",
    "    filtered_labels_pred = labels_pred[valid_indices]\n",
    "\n",
    "    # Evaluate clustering performance using Adjusted Rand Index (ARI)\n",
    "    ari = adjusted_rand_score(filtered_labels_true, filtered_labels_pred)\n",
    "    return ari\n",
    "\n",
    "# List of dimensionality reduction methods to consider\n",
    "reduction_methods = ['SVD', 'UMAP', 'Autoencoder']\n",
    "\n",
    "# Load the pre-computed features and labels\n",
    "filename = './flowers_features_and_labels.npz'\n",
    "data = np.load(filename)\n",
    "X_all, labels_true = data['f_all'], data['y_all']\n",
    "\n",
    "# Define ranges for grid search\n",
    "min_cluster_size_range = [80, 90, 100]\n",
    "min_samples_range = [50]\n",
    "\n",
    "# Perform clustering with each combination of reduction method and parameters\n",
    "results = []\n",
    "for reduction_method in reduction_methods:\n",
    "    for min_cluster_size in min_cluster_size_range:\n",
    "        for min_samples in min_samples_range:\n",
    "            print(reduction_method, min_cluster_size, min_samples)\n",
    "            ari = perform_clustering_with_reduction(reduction_method, X_all, labels_true,\n",
    "                                                    min_cluster_size=min_cluster_size,\n",
    "                                                    min_samples=min_samples)\n",
    "            print ('ari:', ari)\n",
    "            results.append((reduction_method, min_cluster_size, min_samples, ari))\n",
    "\n",
    "# Find the best parameters based on maximum ARI\n",
    "best_params = None\n",
    "best_ari = -1\n",
    "for reduction_method, min_cluster_size, min_samples, ari in results:\n",
    "    if ari > best_ari:\n",
    "        best_ari = ari\n",
    "        best_params = (reduction_method, min_cluster_size, min_samples)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzLn4Pb534B4"
   },
   "source": [
    "### Question 24 (answer)\n",
    "According to the result of above two cells, UMAP followed by HSBSCAN with min_samples=50 and min_cluster_size = 80 results in 5 clusters and 1312 data points detected as noise. The Rand score of 0.62 is achieved. On the other hand, other clustering methods cluster all the points and don't put aside some of the points as noise, therefore their score is lower. Among the other clustering methods, KMeans result in the highest Rand Score of 0.41 with all the points being clusterd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VwtJtluk6_y7"
   },
   "source": [
    "## MLP classifier\n",
    "### QUESTION 25:\n",
    "Report the test accuracy of the MLP classifier on the original VGG features. Report the same when using the reduced-dimension features (you have freedom in choosing the dimensionality reduction algorithm and its parameters). Does the performance of the model suffer with the reduced-dimension representations? Is it significant? Does the success in classification make sense in the context of the clustering results obtained for the same features in Question 24.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "2hofqJEl4Cqd"
   },
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(num_features, 1280),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1280, 640),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(640, 5),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "        # self.cuda()\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.model(X)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        # X = torch.tensor(X, dtype=torch.float32, device='cuda')\n",
    "        # y = torch.tensor(y, dtype=torch.int64, device='cuda')\n",
    "        X = torch.tensor(X, dtype=torch.float32)\n",
    "        y = torch.tensor(y, dtype=torch.int64)\n",
    "\n",
    "        self.model.train()\n",
    "\n",
    "        criterion = nn.NLLLoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "        dataset = TensorDataset(X, y)\n",
    "        dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "        for epoch in tqdm(range(100)):\n",
    "            for (X_, y_) in dataloader:\n",
    "                optimizer.zero_grad()  # Zero out gradients\n",
    "                outputs = self.model(X_)  # Forward pass\n",
    "                loss = criterion(outputs, y_)  # Compute loss\n",
    "                loss.backward()  # Backpropagation\n",
    "                optimizer.step()  # Update model parameters\n",
    "\n",
    "        return self\n",
    "\n",
    "    def eval(self, X_test, y_test):\n",
    "        # Convert inputs and labels to torch tensors and move to GPU\n",
    "        X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "        y_test = torch.tensor(y_test, dtype=torch.int64)\n",
    "\n",
    "        self.model.eval()  # Set model to evaluation mode\n",
    "        correct = 0\n",
    "\n",
    "        # Evaluate the model on test data\n",
    "        with torch.no_grad():  # Disable gradient computation\n",
    "            outputs = self.model(X_test)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct = (predicted == y_test).sum().item()\n",
    "\n",
    "        accuracy = correct / len(y_test)  # Calculate accuracy\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "JMXaur30CVL1"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, labels_true, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6drNV5VkB3CE",
    "outputId": "54b8af3d-4ca0-482f-eb5b-d02f154ae00a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [03:36<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8999\n"
     ]
    }
   ],
   "source": [
    "# test accuracy of the MLP classifier on the original VGG features\n",
    "num_features = X_train.shape[1]\n",
    "model = MLP(num_features)\n",
    "model.train(X_train, y_train)\n",
    "accuracy = model.eval(X_test, y_test)  # Evaluate the model on test data\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7e7IYBNNOui4",
    "outputId": "a51414d0-4a96-465f-b5c8-012702caa771"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/umap/umap_.py:1945: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n",
      "100%|██████████| 100/100 [01:05<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7800\n"
     ]
    }
   ],
   "source": [
    "# test accuracy of the MLP classifier when using the UMAP reduced-dimension features\n",
    "reducer = UMAP(n_components=50, random_state=42)\n",
    "X_train_reduced = reducer.fit_transform(X_train)\n",
    "num_features = X_train_reduced.shape[1]\n",
    "model = MLP(num_features)\n",
    "model.train(X_train_reduced, y_train)\n",
    "\n",
    "X_test_reduced = reducer.transform(X_test)\n",
    "accuracy = model.eval(X_test_reduced, y_test)  # Evaluate the model on test data\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "erFknQ9gbQZZ"
   },
   "source": [
    "### QUESTION 25 (answer):\n",
    "The success in classification and clustering can have differing outcomes when utilizing reduced dimensions of the same feature set. In this context, we observed a decrease in the test accuracy of the classification model when using reduced dimensions, from 89% to 78%. This decrease of 10% in accuracy indicates that the performance of the classification model was notably impacted by the dimensionality reduction.\n",
    "\n",
    "Conversely, the behavior of the clustering model varied with the reduction in feature dimensions. The Adjusted Rand Index (ARI) for clustering, which measures the agreement between true class labels and cluster assignments, improved significantly from 0.19 to 0.41 when reducing the dimensionality of the feature set.\n",
    "\n",
    "These contrasting results highlight an important distinction between classification and clustering tasks concerning the impact of feature dimensionality. While clustering benefited from the reduced dimensionality, as evidenced by the improved ARI, the classification model's performance suffered. This discrepancy underscores the nuanced relationship between feature representation, model complexity, and task-specific requirements in machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UJHhZtikbPKB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
